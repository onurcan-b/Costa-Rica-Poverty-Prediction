{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group: The Order of the PyTorch\n",
    "### Milestone 1\n",
    "\n",
    "- Members: Onur Buyukkalkan, Yi-Huai Chang, Diyanet Nijiati\n",
    "\n",
    "- Project: Costa Rica Household Poverty Prediction\n",
    "\n",
    "https://www.kaggle.com/competitions/costa-rican-household-poverty-prediction/overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Explore the Data\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Shape and NA Values Across Columns\n",
    "print(\"Data shape:\", data.shape)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None) \n",
    "print(data.isnull().sum())\n",
    "\n",
    "#v2a1, v18q1, rez_esc have too many null values, is this a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts of the Target Labels\n",
    "print(data['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Plotting\n",
    "\n",
    "We should now visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of the poverty levels\n",
    "sns.countplot(x='Target', data=data)\n",
    "plt.title('Distribution of Poverty Levels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation matrix\n",
    "numeric_data = data.select_dtypes(include=[np.number])  # np.number covers integers and floats\n",
    "\n",
    "# Now compute the correlation matrix\n",
    "corr_matrix = numeric_data.corr()\n",
    "\n",
    "# Assuming 'corr_matrix' is your correlation matrix\n",
    "sns.set(style=\"white\")  # Set style to 'white' to ensure labels are clear\n",
    "\n",
    "plt.figure(figsize=(12, 10))  # Adjust figure size to your preference\n",
    "ax = sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=False,\n",
    "    cmap='coolwarm',\n",
    "    cbar=True,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True\n",
    ")\n",
    "\n",
    "# Rotate the labels on the x-axis for better visibility\n",
    "plt.xticks(rotation=90, fontsize=8)  # Rotate x labels and set font size\n",
    "plt.yticks(rotation=0, fontsize=8)  # Rotate y labels and set font size (if needed)\n",
    "\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "#We see that hhsize, tamhog, r4t3,hogar_total are the same thing by looking at the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning\n",
    "\n",
    "We can fill n/a values with mean for consistency or maybe just drop all n/a values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = data.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0]\n",
    "print(missing_data.sort_values(ascending=False))\n",
    "\n",
    "# Impute missing values with the median\n",
    "for column in missing_data.index:\n",
    "    if data[column].dtype != 'object':  # assuming only numeric columns need imputation\n",
    "        data[column].fillna(data[column].median(), inplace=True)\n",
    "\n",
    "# Dropping columns with more than 70% missing values\n",
    "for column in missing_data.index:\n",
    "    if missing_data[column] > 0.7 * len(data):\n",
    "        data.drop(columns=[column], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Features to Integers\n",
    "# Convert edjefe and edjefa to dummy variables\n",
    "# Make your own dependency rate\n",
    "#???????????????????????\n",
    "\n",
    "\n",
    "#Group by household before or after prediction, rounding the final label up and down for each household mean to find the target label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Exclude 'Target' from numeric columns, now safely assuming all are numeric\n",
    "numeric_cols = numeric_cols.drop('Target', errors='ignore')  # Use errors='ignore' to avoid KeyErrors if the column is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler and transform the data\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Check the transformed data\n",
    "print(data[numeric_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[numeric_cols].mean())\n",
    "print(data[numeric_cols].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final datatype and na check\n",
    "print(data.dtypes)\n",
    "\n",
    "print(data.isnull().sum().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by idhogar\n",
    "household_avg = data.groupby('idhogar')[numeric_cols].mean()\n",
    "\n",
    "# Display the result\n",
    "print(household_avg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Selection\n",
    "\n",
    "The features that are available to us are described here: https://www.kaggle.com/competitions/costa-rican-household-poverty-prediction/data\n",
    "\n",
    "We have a number of different features from material amenities like toilet and source of electricity to household characteristics like disability, number of kids, years in education etc. These are indirect features that might reflect the quality of life for these households.\n",
    "\n",
    "We can use the outside wall material, roof material, number of tablets owned, toilet situation, electricity source etc. We can also create children to adult ratio, income per children, income per person in household, but we do not have income data. We can therefore find replacements that will still represent the level of income. \n",
    "\n",
    "#### Potential New Features \n",
    "\n",
    "- **Ratio of Children to Adults**: This can highlight households that may be under more financial strain.\n",
    "\n",
    "- **Dependency Ratio**: Although itâ€™s already provided, checking for its accurate calculation or recalculating might be useful if there are any discrepancies.\n",
    "\n",
    "- **Asset Index**: Create a composite score based on the presence of assets (e.g., refrigerator, computer, tablet, TV) and home characteristics (types of walls, floors, and roof materials). This score can serve as a proxy for economic status.\n",
    "\n",
    "- **Educational Level Index**: A score representing the overall educational attainment within the household.\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- Underreporting or overreporting to get financial assistance.\n",
    "- Lack of monetary income and asset reported.\n",
    "- Dimensionality problem might arise if we fail to find the most important features and eliminate the lesser important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Out Indexes\n",
    "\n",
    "# Example of creating an Asset Index\n",
    "data['asset_index'] = (data['refrig'] + data['v18q'] + data['computer'] + data['television'] + data['mobilephone']).astype(int)\n",
    "\n",
    "# Example of creating an Educational Level Index\n",
    "data['education_index'] = (data['instlevel1'] + data['instlevel2']*2 + data['instlevel3']*3 + data['instlevel4']*4 + data['instlevel5']*5 + data['instlevel6']*6 + data['instlevel7']*7 + data['instlevel8']*8 + data['instlevel9']*9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% temporary set\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary set into 10% validation and 20% test set\n",
    "# Since the temp_data is 30% of the data, we take 1/3 of it for validation (which is 10% of the total data)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=2/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set size: \", train_data.shape)\n",
    "print(\"Validation set size: \", validation_data.shape)\n",
    "print(\"Test set size: \", test_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
